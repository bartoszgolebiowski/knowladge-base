# S3

**Amazon Simple Storage Service (S3) - Summary Notes**

## **Core Concepts**

- **Object Storage:** Designed for storing objects (files and metadata).
- **Serverless:** No underlying infrastructure to manage.
- **Unlimited Storage:** Provides virtually unlimited storage capacity.
- **Pay-as-you-go:** You only pay for the storage you consume and the requests you make.
- **Static Content Hosting:** Well-suited for hosting static website content.
- **Key-Based Access:** Objects are accessed using a unique key.
- **No Native Indexing:** S3 itself does not provide indexing. DynamoDB can be used for indexing S3 objects.
- **Not a File System:** Cannot be mounted directly on EC2 instances. Use EFS for file system needs.

## **Anti-Patterns**

- **Lots of Small Files:** Can lead to higher request costs and potentially impact performance.
- **POSIX File System Requirements:** Use EFS for POSIX compliance (file permissions, etc.).
- **File Locking:** S3 does not support file locking mechanisms.
- **Search Feature/Queries:** Lacks built-in search or querying capabilities over object content.
- **Rapidly Sharing Data:** While sharing is possible, it's not optimized for highly dynamic, real-time sharing.
- **Website with Extensive Dynamic Content:** Primarily for static content; dynamic content typically requires backend processing.

## **S3 Storage Classes**

- **Standard:** High availability, high durability, frequently accessed data.
- **Intelligent-Tiering:** Automatically moves data between frequent and infrequent access tiers based on usage patterns to optimize costs.
    
    **1**
    
- **Standard-IA (Infrequent Access):** Lower storage cost, higher retrieval cost, for less frequently accessed data.
- **One Zone-IA:** Lower cost than Standard-IA, stored in a single AZ, lower availability and durability.
- **Glacier Instant Retrieval:** Low-cost, long-term storage with millisecond retrieval.
- **Glacier Flexible Retrieval (formerly Glacier):** Very low-cost, long-term storage with configurable retrieval times (minutes to hours).
- **Glacier Deep Archive:** Lowest-cost, long-term archival storage with retrieval times of hours.

## **S3 Lifecycle Policies**

- **Transitioning Objects:** Automate moving objects between different storage classes based on age or access patterns.
- **Object Expiration:** Automatically delete objects after a specified period.

## **S3 Replication**

- **Versioning Requirement:** Versioning must be enabled on the source bucket.
- **CRR (Cross-Region Replication):** Replicates objects between S3 buckets in different AWS regions.
    - Fast replication.
    - Can be combined with Lifecycle Rules on the target bucket (tiers are not replicated by default).
    - Benefits: Reduced latency for global access, disaster recovery, security.
- **SRR (Same-Region Replication):** Replicates objects between S3 buckets within the same AWS region.
    - Benefits: Compliance requirements, log aggregation, live data replication for testing.
- **S3 Replication Time Control (S3 RTC):** Guarantees that most objects will be replicated within seconds, and 99.99% within 15 minutes. Provides CloudWatch metrics and alarms for objects exceeding the threshold. Useful for compliance and disaster recovery with strict timelines.

## **S3 Event Notifications**

- **Reacting to Bucket Events:** Allows triggering actions based on events within an S3 bucket.
- **Supported Events:** `s3:ObjectCreated`, `s3:ObjectRemoved`, `s3:ObjectRestore`, `s3:Replication`.
- **Object Name Filtering:** Notifications can be filtered based on object key prefixes or suffixes (e.g., only notify for JPEG files).
- **Destinations:** Can send notifications to:
    - SNS (Simple Notification Service)
    - SQS (Simple Queue Service)
    - Lambda Functions
- **Typical Delivery Time:** Usually within seconds, but can take a minute or longer.

## **S3 Event Notifications with Amazon EventBridge**

- **Enhanced Event Management:** Integrates S3 events with Amazon EventBridge for more powerful event routing and processing.
- **Centralized Event Bus:** All S3 events are shared with EventBridge.
- **Extensive Destinations:** EventBridge can route events to over 18 AWS services.
- **Advanced Filtering:** Supports complex filtering using JSON rules (including metadata, object size, etc.).
- **Multiple Destinations per Rule:** A single EventBridge rule can send events to multiple targets (e.g., Step Functions, Kinesis Streams/Firehose).
- **Improved Reliability and Visibility:** Offers archive and replay capabilities for events, and more reliable delivery.

## **S3 Performance**

- **Automatic Scaling:** S3 automatically scales to handle high request rates.
- **Latency:** Typically 100-200 milliseconds for the first byte.
- **Request Rate Limits (per prefix):**
    - 3,500 PUT/COPY/POST/DELETE requests per second.
    - 5,500 GET/HEAD requests per second.
- **Prefix Importance:** Performance scales per prefix within a bucket. Distributing reads/writes across multiple prefixes can significantly increase throughput.
    - **Prefix Example:** For `bucket/folder1/sub1/file`, the prefix is `/folder1/sub1/`.

### **Performance Optimizations for Uploads**

- **Multi-Part Upload:** Recommended for files over 100 MB and mandatory for files over 5 GB.
    - Parallelizes uploads by dividing the file into smaller parts.
    - Improves transfer speed and resilience to network interruptions (individual parts can be retried).
    - S3 reconstructs the file after all parts are uploaded.
- **S3 Transfer Acceleration:** Increases upload speed by routing traffic through AWS edge locations.
    - Data is first uploaded to the nearest edge location, which then transfers it to the S3 bucket over the AWS internal network.
    - Compatible with Multi-Part Upload.

### **Performance Optimizations for Downloads**

- **S3 Byte-Range Fetches:** Allows downloading specific ranges of bytes from an object in parallel.
    - Improves download speed by utilizing more bandwidth.
    - Enhances resilience as only failed ranges need to be re-requested.
    - Enables retrieving partial data (e.g., the header of a file), saving cost and bandwidth.

## **Removing Incomplete Multi-Part Uploads**

- **Problem:** Incomplete Multi-Part Uploads can leave orphaned parts in the S3 bucket, incurring storage costs.
- **Solution:** Use S3 Lifecycle Policies to automatically abort incomplete Multi-Part Uploads after a specified number of days since initiation.
- **Manual Initiation:** Can also be managed using CLI/API calls to list and complete/abort Multi-Part Uploads.