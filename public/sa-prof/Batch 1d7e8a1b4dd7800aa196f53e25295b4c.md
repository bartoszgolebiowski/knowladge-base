# Batch

# **AWS Batch**

## **Purpose and Goals**

- Run batch jobs as Docker images.
- Two compute environment options: Fargate (serverless) or dynamic EC2/Spot Instance provisioning.
- Automate the management of compute resources for batch workloads.
- Pay only for the underlying resources used (Fargate vCPU/memory or EC2 instances).

## **Key Concepts**

- **Batch Job:** A unit of work to be executed. Defined as a Docker image.
- **Job Definition:** Specifies the Docker image to use, resource requirements (CPU, memory), environment variables, and other job parameters.
- **Job Queue:** A queue where submitted jobs reside until they are scheduled to run on a Compute Environment.
- **Compute Environment:** A set of compute resources (EC2 instances or Fargate) where batch jobs are executed.
    - **Managed Compute Environment:** AWS Batch manages the capacity and instance types. Supports On-Demand and Spot Instances with optional maximum price for Spot.
    - **Unmanaged Compute Environment:** You control and manage the instance configuration, provisioning, and scaling.
- **Job Submission:** Jobs are submitted to a Job Queue using the AWS SDK.
- **Task Definition (ECS):** While the speaker mentions ECS managing the Batch job, it's more accurate to say that Batch orchestrates the running of Docker containers on either EC2 (managed by ECS under the hood) or Fargate. The Job Definition encapsulates the container configuration.

## **Use Cases**

- Batch processing of images.
- Running thousands of concurrent jobs.
- Scheduled batch jobs (using Amazon EventBridge).
- Orchestrated batch workflows (using AWS Step Functions).

## **Solution Architecture Example: Thumbnail Generation**

1. **User uploads images to Amazon S3.**
2. **Triggering Batch Job (Two Options):**
    - **Option 1: S3 Event Notification -> Lambda Function -> AWS SDK (Start Batch Job).**
    - **Option 2: S3 Event Notification -> Amazon EventBridge -> AWS Batch (direct integration).** This offers more filtering and a serverless approach for triggering.
3. **Batch Job Execution:**
    - A Docker image is pulled from Amazon ECR.
    - The code within the container runs.
    - The job retrieves the image from S3 (requires correct IAM role).
    - The image is processed (thumbnail creation).
    - The thumbnail is sent to a target S3 bucket.
    - Metadata might be inserted into Amazon DynamoDB (requires correct IAM role).

## **Lambda vs. Batch**

| **Feature** | **AWS Lambda** | **AWS Batch** |
| --- | --- | --- |
| Time Limit | Limited runtime | No time limits |
| Runtimes | Built-in runtimes, special container images | Any runtime packaged as a standard Docker image |
| Disk Space | Limited temporary disk space | Relies on EBS or instance store for EC2, or ephemeral storage for Fargate |
| Serverless | Fully serverless | Serverless with Fargate; relies on EC2 instances (managed or unmanaged) |
| Flexibility | Less flexibility in runtime and execution environment | More flexibility with Docker images and runtime choices |
| Use Cases | Event-driven, short-lived tasks, real-time processing | Batch processing, long-running tasks, high-performance computing |

## **Compute Environments in Detail**

### **1. Managed Compute Environment**

- AWS Batch manages capacity and instance types.
- Choose between On-Demand and Spot Instances.
- Set a maximum price for Spot Instances.
- AWS handles scaling the capacity based on job queue demand.
- Instances are launched within your VPC.
- **Networking Considerations:**
    - Private subnets require access to the ECS service via NAT Gateway/Instance or VPC Endpoint for ECS.

### **2. Unmanaged Compute Environment**

- You control and manage instance configuration, provisioning, and scaling.
- More responsibility for managing the underlying infrastructure.
- You pay for your provisioned instances.

## **Managed Compute Environment Workflow**

1. **Define Min/Max vCPU:** Set the desired minimum and maximum vCPU capacity for the environment.
2. **Specify Spot Instance Options:** Choose whether to use Spot Instances and set a maximum price.
3. **AWS Batch Manages Instances:** Based on the vCPU limits and Spot preferences, Batch launches and manages EC2 instances of various types within your VPC.
4. **Batch Job Queue:** Jobs submitted to the queue are distributed to the available EC2 instances in the Compute Environment.
5. **Job Submission:** Use the AWS SDK to add jobs to the Job Queue (can be triggered by Lambda, EventBridge, Step Functions).
6. **Auto Scaling:** The Managed Compute Environment automatically scales the number of EC2 instances (On-Demand or Spot) up or down based on the number of pending jobs in the queue.

## **Multi Node Parallel (MNP) Jobs for High Performance Computing (HPC)**

- Allows a single batch job to span multiple EC2 or ECS instances simultaneously.
- Ideal for tightly coupled workloads requiring parallel processing for faster completion.
- Represents a single job utilizing multiple nodes.
- One **main node** manages one or more **child nodes**.
- **Limitations:**
    - **Does not work with Spot Instances (currently).**
    - **Recommended to use a "cluster" placement group** for enhanced networking (instances on the same rack within the same AZ).
- **Workflow:**
    - Create a "cluster" placement group.
    - Submit a Multi Node job specifying the number of nodes.
    - AWS Batch launches one main EC2 instance and the specified number of child EC2 instances within the placement group.
    - The main node orchestrates the work across the child nodes.
    - All instances are terminated after the job completes.